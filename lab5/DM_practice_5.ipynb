{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOA9MOth2oPN"
   },
   "source": [
    "# **Лабораторна робота 5: Використання Boosting моделей для прогнозування**\n",
    "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**\n",
    "\n",
    "**Лабораторні роботи де в коді буде використаня КИРИЛИЦІ будуть оцінюватись в 20 балів.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dldF036z3ojM"
   },
   "source": [
    "#### **Мета роботи:**\n",
    "Ознайомитись з принципами роботи Boosting моделей, навчитися застосовувати три різні Boosting алгоритми (AdaBoost, Gradient Boosting, XGBoost) для розв'язання задач прогнозування, налаштовувати параметри моделей, зокрема параметри регуляризації, для підвищення їх продуктивності.\n",
    "\n",
    "#### **Завдання:**\n",
    "\n",
    "1. **Підготовка даних**:\n",
    "   - Завантажте та підготуйте датасет для регресії або класифікації: (наприклад, **[дані про ціни на житло](https://)** або **[діабет](https://www.kaggle.com/datasets/pkdarabi/diabetes-dataset-with-18-features)**). Розбийте дані на навчальну та тестову вибірки (наприклад, 80/20).\n",
    "   \n",
    "2. **Побудова трьох Boosting моделей**:\n",
    "   - **AdaBoost**: Побудуйте модель на базі дерев рішень як базових моделей.\n",
    "   - **Gradient Boosting**: Використайте бібліотеку Scikit-learn для створення Gradient Boosting моделі для прогнозування.\n",
    "   - **XGBoost**: Використайте бібліотеку XGBoost для побудови більш оптимізованої моделі.\n",
    "\n",
    "3. **Навчання та оцінка моделей**:\n",
    "   - Для кожної моделі виведіть метрики оцінки, такі як точність (classification accuracy) або середньоквадратична помилка (MSE) для регресії.\n",
    "   - Побудуйте графіки навчання для візуалізації процесу.\n",
    "\n",
    "4. **Тонке налаштування параметрів (Hyperparameter Tuning)**:\n",
    "   - Для кожної моделі налаштуйте наступні параметри:\n",
    "     - **AdaBoost**: Кількість базових моделей (n_estimators), learning_rate.\n",
    "     - **Gradient Boosting**: Максимальна глибина дерев (max_depth), кількість дерев (n_estimators), learning_rate.\n",
    "     - **XGBoost**: Кількість дерев (n_estimators), learning_rate, max_depth, subsample.\n",
    "   - Використайте крос-валідацію для підбору оптимальних параметрів.\n",
    "\n",
    "5. **Регуляризація**:\n",
    "   - Додайте **L1 та L2 регуляризацію** для Gradient Boosting та XGBoost моделей (в XGBoost параметри `alpha` для L1 та `lambda` для L2).\n",
    "   - Виведіть результати з регуляризацією і порівняйте з результатами без регуляризації.\n",
    "\n",
    "6. **Порівняння моделей**:\n",
    "   - Проведіть порівняння трьох моделей за основними метриками продуктивності на тестових даних.\n",
    "   - Проаналізуйте, як регуляризація впливає на результати моделей. В яких випадках вона покращує модель, а в яких — погіршує.\n",
    "\n",
    "7. **Захист роботи**:\n",
    "   - Поясніть, яку модель і чому ви вважаєте найкращою для вирішення вашої задачі.\n",
    "   - Опишіть, як впливала регуляризація на продуктивність моделей, та що б ви змінили в параметрах для кращого результату.\n",
    "\n",
    "#### **Додаткові вимоги:**\n",
    "- Забезпечити відображення важливості ознак у кожній з моделей (feature importance).\n",
    "- Побудувати графіки для візуалізації залежності продуктивності від зміни гіперпараметрів (наприклад, залежність від кількості дерев або learning_rate).\n",
    "\n",
    "\n",
    "#### **Додаткові набори даних:**\n",
    "\n",
    "1. **Diabetes Dataset** — містить медичні дані пацієнтів, які можуть бути використані для прогнозування наявності діабету. Він доступний за посиланням: [Diabetes Dataset](https://www.kaggle.com/datasets/mathchi/diabetes-data-set).\n",
    "\n",
    "2. **Diabetes Health Indicators Dataset** — великий датасет з понад 250 тисячами записів, який містить індикатори здоров'я для визначення ризику діабету. Підходить для класифікаційних задач. Доступний за посиланням: [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset).\n",
    "\n",
    "3. **California Housing Prices** — датасет, що містить інформацію про ціни на житло у різних округах штату Каліфорнія, включаючи такі параметри, як середній дохід домогосподарств, кількість мешканців тощо. Він добре підходить для регресійних моделей. Доступний за посиланням: [California Housing Prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "4. **House Prices - Advanced Regression Techniques** — більш комплексний датасет, який використовується для вдосконалення регресійних моделей. Включає більше 70 ознак, що описують різні аспекти нерухомості, ідеальний для глибокого аналізу та тонкого налаштування моделей. Доступний тут: [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques).\n",
    "\n",
    "Ці набори даних ви також можете використовувати для виконання завдань Лабораторної роботи 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "JMM1ar4a2lz8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "X = data[['Age', 'Gender', 'BMI', 'SBP', 'DBP', 'FPG', 'Chol', 'Tri', 'HDL', 'LDL', 'ALT', 'BUN', 'CCR', 'FFPG', 'smoking', 'drinking', 'family_histroy']]\n",
    "y = data['Diabetes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy AdaBoost: 0.9186991869918699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.1, algorithm='SAMME', random_state=42)\n",
    "model_ada.fit(X_train, y_train)\n",
    "y_pred_ada = model_ada.predict(X_test)\n",
    "print('Accuracy AdaBoost:', accuracy_score(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Gradient Boosting: 0.9442508710801394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gb = GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "model_gb.fit(X_train, y_train)\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "print('Accuracy Gradient Boosting:', accuracy_score(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy XGBoost: 0.9454123112659698\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, subsample=0.8, reg_alpha=0.1, reg_lambda=1, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "print('Accuracy XGBoost:', accuracy_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    model_gb = GradientBoostingClassifier(n_estimators=i, learning_rate=0.1)\n",
    "    model_gb.fit(X_train, y_train)\n",
    "    train_errors.append(mean_squared_error(y_train, model_gb.predict(X_train)))\n",
    "    test_errors.append(mean_squared_error(y_test, model_gb.predict(X_test)))\n",
    "\n",
    "plt.plot(range(1, 30), train_errors, label='Training Error')\n",
    "plt.plot(range(1, 30), test_errors, label='Test Error')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best Parameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.943089430894309\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=150, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=3, \n",
    "    reg_alpha=0.1,  # L1\n",
    "    reg_lambda=1.0,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [125, 150, 200, 250],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'learning_rate': [0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best Parameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 190}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [125, 130, 190, 200, 210],\n",
    "    'max_depth': [3, 10],\n",
    "    'learning_rate': [0.01, 0.02, 0.04]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best Parameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.009, 'max_depth': 4, 'n_estimators': 180}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [180, 185, 190, 195],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.009, 0.01, 0.011, 0.012]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best Parameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.943089430894309\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=180, \n",
    "    learning_rate=0.009, \n",
    "    max_depth=34, \n",
    "    reg_alpha=0.1,  # L1\n",
    "    reg_lambda=1.0,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 and L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.9419279907084785\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=180, \n",
    "    learning_rate=0.009, \n",
    "    max_depth=4, \n",
    "    reg_alpha=0.2,  # L1\n",
    "    reg_lambda=2.0,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.943089430894309\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=180, \n",
    "    learning_rate=0.009, \n",
    "    max_depth=4, \n",
    "    reg_alpha=0.5,  # L1\n",
    "    reg_lambda=1.5,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.943089430894309\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=180, \n",
    "    learning_rate=0.009, \n",
    "    max_depth=4, \n",
    "    reg_alpha=0.1,  # L1\n",
    "    reg_lambda=1.5,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.943089430894309\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=180, \n",
    "    learning_rate=0.009, \n",
    "    max_depth=4, \n",
    "    reg_alpha=0.1,  # L1\n",
    "    reg_lambda=1.3,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.9419279907084785\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=180, \n",
    "    learning_rate=0.009, \n",
    "    max_depth=4, \n",
    "    reg_alpha=0.1,  # L1\n",
    "    reg_lambda=5,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost with Regularization): 0.9419279907084785\n"
     ]
    }
   ],
   "source": [
    "model_xgb_reg = XGBClassifier(\n",
    "    n_estimators=180, \n",
    "    learning_rate=0.009, \n",
    "    max_depth=4, \n",
    "    reg_alpha=0.8,  # L1\n",
    "    reg_lambda=1.3,  # L2\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy (XGBoost with Regularization):', accuracy_score(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost:         0.9454, XGBoost(with R): 0.9419. The difference is lesss than 1%.\n",
    "\n",
    "Based on this data I can say that with regularization it's arguably slightly worse. Having tried different values for alfa and lambda can confidently say that in current case regularization does NOT improve accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost performance metrics:\n",
      "Accuracy: 0.9187\n",
      "Precision: 1.0000\n",
      "Recall: 0.7046\n",
      "F1-Score: 0.8267\n",
      "\n",
      "Gradient boosting performance petrics:\n",
      "accuracy: 0.9443\n",
      "precision: 0.9479\n",
      "recall: 0.8439\n",
      "F1-score: 0.8929\n",
      "\n",
      "XGBoost performance metrics:\n",
      "Accuracy: 0.9454\n",
      "Precision: 0.9524\n",
      "Recall: 0.8439\n",
      "F1-score: 0.8949\n",
      "\n",
      "XGBoost with regularization performance metrics:\n",
      "Accuracy: 0.9419\n",
      "Precision: 0.9431\n",
      "Recall: 0.8397\n",
      "F1-Score: 0.8884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"AdaBoost performance metrics:\")\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_ada:.4f}\")\n",
    "print(f\"Precision: {precision_ada:.4f}\")\n",
    "print(f\"Recall: {recall_ada:.4f}\")\n",
    "print(f\"F1-Score: {f1_ada:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Gradient boosting performance petrics:\")\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "precision_gb = precision_score(y_test, y_pred_gb)\n",
    "recall_gb = recall_score(y_test, y_pred_gb)\n",
    "f1_gb = f1_score(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"accuracy: {accuracy_gb:.4f}\")\n",
    "print(f\"precision: {precision_gb:.4f}\")\n",
    "print(f\"recall: {recall_gb:.4f}\")\n",
    "print(f\"F1-score: {f1_gb:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"XGBoost performance metrics:\")\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"Precision: {precision_xgb:.4f}\")\n",
    "print(f\"Recall: {recall_xgb:.4f}\")\n",
    "print(f\"F1-score: {f1_xgb:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"XGBoost with regularization performance metrics:\")\n",
    "accuracy_xgb_reg = accuracy_score(y_test, y_pred_xgb_reg)\n",
    "precision_xgb_reg = precision_score(y_test, y_pred_xgb_reg)\n",
    "recall_xgb_reg = recall_score(y_test, y_pred_xgb_reg)\n",
    "f1_xgb_reg = f1_score(y_test, y_pred_xgb_reg)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_xgb_reg:.4f}\")\n",
    "print(f\"Precision: {precision_xgb_reg:.4f}\")\n",
    "print(f\"Recall: {recall_xgb_reg:.4f}\")\n",
    "print(f\"F1-Score: {f1_xgb_reg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking to the account the fact that it's the medical field, and it's more important not to miss any patiants having diabetes I say AdaBoost has the best performing model with perfect 1.0 score. Even thought it's accuracy is the lowest between all, I think it's better to double check someone who doesn't have the problem than miss one. In current situation is focusing on the mistakes through iterations of creating the AdaBoost model resulted in the best percision result."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
